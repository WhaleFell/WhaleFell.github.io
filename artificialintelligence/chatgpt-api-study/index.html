<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"><meta name="HandheldFriendly" content="True"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><link rel="shortcut icon" href="/images/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico"><link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico"><link rel="mask-icon" href="/images/favicon.ico"><title>ChatGPT API 学习笔记 | 😊落落のBlog😊</title><meta name="keywords" content="AI, ChatGPT, 人工智能, 编程,博客,记录,技术,生活,前端,摄影,LGBT,计算机,网络安全,Life,Cybersecurity,Python,Golang,Vue,Javascript,Java,Linux"><meta name="description" content="ChatGPT API 学习笔记Reference Openai Offical Document  ConceptsGPT or ChatGPTOpenAI’s text generation models (often referred to as generative pre-trained transformers or “GPT” models for short) OpenAI 的文本"><meta property="og:type" content="article"><meta property="og:title" content="ChatGPT API 学习笔记"><meta property="og:url" content="https://www.whaleluo.top/artificialintelligence/chatgpt-api-study/index.html"><meta property="og:site_name" content="😊落落のBlog😊"><meta property="og:description" content="ChatGPT API 学习笔记Reference Openai Offical Document  ConceptsGPT or ChatGPTOpenAI’s text generation models (often referred to as generative pre-trained transformers or “GPT” models for short) OpenAI 的文本"><meta property="og:locale"><meta property="article:published_time" content="2023-09-19T13:44:19.000Z"><meta property="article:modified_time" content="2023-09-19T13:44:19.000Z"><meta property="article:author" content="WhaleFall"><meta property="article:tag" content="AI"><meta property="article:tag" content="ChatGPT"><meta property="article:tag" content="人工智能"><meta name="twitter:card" content="images&#x2F;favicon.ico"><link rel="stylesheet" href="/css/style/main.css"><link rel="stylesheet" id="hl-default-theme" href="https://api.whaleluo.top/file/?url=https://cdn.jsdelivr.net/npm/highlight.js@10.1.2/styles/atom-one-light.css" media="none"><link rel="stylesheet" id="hl-dark-theme" href="https://api.whaleluo.top/file/?url=https://cdn.jsdelivr.net/npm/highlight.js@10.1.2/styles/atom-one-dark.css" media="none"><link rel="stylesheet" href="/css/style/dark.css"><script src="/js/darkmode.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests"><meta name="google-site-verification" content="bka9Mdyvo7g1v-jQq8CzqcaY9zE2QGltMwsvO63rAUw"><meta name="generator" content="Hexo 7.1.1"><link rel="alternate" href="/atom.xml" title="😊落落のBlog😊" type="application/atom+xml"></head><body><div id="app" tabindex="-1"><header class="header"><div class="header__left"><a href="/" class="button"><span class="logo__text">落落のBlog</span></a></div><div class="header__right"><div class="navbar__menus"><a href="/" class="navbar-menu button">首页</a> <a href="/tags/" class="navbar-menu button">标签</a> <a href="/archives/" class="navbar-menu button">归档</a> <a href="/categories/" class="navbar-menu button">主题</a> <a href="/friends/" class="navbar-menu button">友链</a> <a href="/about/" class="navbar-menu button">关于</a> <a href="/event/" class="navbar-menu button">大事记</a> <a href="/atom.xml" class="navbar-menu button">RSS</a></div><a href="/search/" id="btn-search"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="24" height="24" fill="currentColor" stroke="currentColor" stroke-width="32"><path d="M192 448c0-141.152 114.848-256 256-256s256 114.848 256 256-114.848 256-256 256-256-114.848-256-256z m710.624 409.376l-206.88-206.88A318.784 318.784 0 0 0 768 448c0-176.736-143.264-320-320-320S128 271.264 128 448s143.264 320 320 320a318.784 318.784 0 0 0 202.496-72.256l206.88 206.88 45.248-45.248z"></path></svg> </a><a href="javaScript:void(0);" id="btn-toggle-dark"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path></svg> </a><a class="dropdown-icon button" id="btn-dropdown" tabindex="0"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" width="24" height="24" fill="none" stroke="currentColor" stroke-width="0.7" stroke-linecap="round" stroke-linejoin="round"><path fill="currentColor" d="M3.314,4.8h13.372c0.41,0,0.743-0.333,0.743-0.743c0-0.41-0.333-0.743-0.743-0.743H3.314c-0.41,0-0.743,0.333-0.743,0.743C2.571,4.467,2.904,4.8,3.314,4.8z M16.686,15.2H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,15.2,16.686,15.2z M16.686,9.257H3.314c-0.41,0-0.743,0.333-0.743,0.743s0.333,0.743,0.743,0.743h13.372c0.41,0,0.743-0.333,0.743-0.743S17.096,9.257,16.686,9.257z"></path></svg></a><div class="dropdown-menus" id="dropdown-menus"><a href="/" class="dropdown-menu button">首页</a> <a href="/tags/" class="dropdown-menu button">标签</a> <a href="/archives/" class="dropdown-menu button">归档</a> <a href="/categories/" class="dropdown-menu button">主题</a> <a href="/friends/" class="dropdown-menu button">友链</a> <a href="/about/" class="dropdown-menu button">关于</a> <a href="/event/" class="dropdown-menu button">大事记</a> <a href="/atom.xml" class="dropdown-menu button">RSS</a></div></div></header><main class="main"><div class="post-title"><h1 class="post-title__text">ChatGPT API 学习笔记</h1><div class="post-title__meta"><a href="/archives/2023/09/" class="post-meta__date button">2023-09-19</a> <span class="separate-dot"></span><a href="/categories/ArtificialIntelligence/" class="button">ArtificialIntelligence</a> <span class="separate-dot"></span><a href="/categories/ArtificialIntelligence/AI/" class="button">AI</a> <span id="busuanzi_container_page_pv" hidden><span class="separate-dot"></span> <span></span> <span id="busuanzi_value_page_pv"></span> <span>Views</span></span></div></div><aside class="post-side"><div class="post-side__toc"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">1.</span> <span class="toc-text">Reference</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Concepts"><span class="toc-number">2.</span> <span class="toc-text">Concepts</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GPT-or-ChatGPT"><span class="toc-number">2.1.</span> <span class="toc-text">GPT or ChatGPT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-%E6%8F%90%E7%A4%BA%E8%AF%8D"><span class="toc-number">2.2.</span> <span class="toc-text">Prompt 提示词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Embedings-%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">Embedings 嵌入模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Token-%E8%AF%8D%E5%85%83-%E4%BB%A3%E5%B8%81"><span class="toc-number">2.4.</span> <span class="toc-text">Token 词元&#x2F;代币</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Large-Multimodal-Model-%E5%A4%A7%E5%9E%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.5.</span> <span class="toc-text">Large Multimodal Model 大型多模态模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DALL-E"><span class="toc-number">2.6.</span> <span class="toc-text">DALL-E</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Text-To-Speech-TTS-%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3"><span class="toc-number">2.7.</span> <span class="toc-text">Text To Speech (TTS) 文本转语音</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Whisper-%E8%80%B3%E8%AF%AD"><span class="toc-number">2.8.</span> <span class="toc-text">Whisper 耳语</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Moderation-%E9%80%82%E5%BA%A6-%E5%AE%A1%E6%9F%A5%E6%A8%A1%E5%9E%8B-censorship-model"><span class="toc-number">2.9.</span> <span class="toc-text">Moderation 适度(审查模型) censorship model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Frequency-and-presence-penalties-penal-adj-%E5%88%91%E4%BA%8B%E7%9A%84-%E9%A2%91%E7%8E%87%E5%92%8C%E5%AD%98%E5%9C%A8%E6%83%A9%E7%BD%9A"><span class="toc-number">2.10.</span> <span class="toc-text">Frequency and presence penalties (penal adj.刑事的) (频率和存在惩罚)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Engineering-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B"><span class="toc-number">2.11.</span> <span class="toc-text">Prompt Engineering 提示词工程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Temperature-Parameter-%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0"><span class="toc-number">2.12.</span> <span class="toc-text">Temperature Parameter 温度参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Function-call-%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8"><span class="toc-number">2.13.</span> <span class="toc-text">Function call 函数调用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fine-tuning-%E5%BE%AE%E8%B0%83-%E7%B2%BE%E7%BB%86%E7%9A%84%E8%B0%83%E6%95%B4"><span class="toc-number">2.14.</span> <span class="toc-text">Fine-tuning (微调) (精细的调整)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Few-Shot-Learning-%E5%B0%91%E6%A0%B7%E6%9C%AC%E8%AE%AD%E7%BB%83"><span class="toc-number">2.15.</span> <span class="toc-text">Few-Shot Learning (少样本训练)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AGI-Artificial-General-Intelligence-%E4%BA%BA%E5%B7%A5%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BD"><span class="toc-number">2.16.</span> <span class="toc-text">AGI (Artificial General Intelligence) 人工通用智能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DPO-Direct-Perfer-Optimal-%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96"><span class="toc-number">2.17.</span> <span class="toc-text">DPO(Direct Perfer Optimal) 直接偏好优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NLP-Natural-Language-Processing-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="toc-number">2.18.</span> <span class="toc-text">NLP(Natural Language Processing) 自然语言处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CV-Computer-Vision-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="toc-number">2.19.</span> <span class="toc-text">CV (Computer Vision) 计算机视觉</span></a></li></ol></li></ol></div></aside><a class="btn-toc button" id="btn-toc" tabindex="0"><svg viewBox="0 0 1024 1024" width="32" height="32" xmlns="http://www.w3.org/2000/svg"><path d="M128 256h64V192H128zM320 256h576V192H320zM128 544h64v-64H128zM320 544h576v-64H320zM128 832h64v-64H128zM320 832h576v-64H320z" fill="currentColor"></path></svg></a><div class="toc-menus" id="toc-menus"><div class="toc-title">Article Directory</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Reference"><span class="toc-number">1.</span> <span class="toc-text">Reference</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Concepts"><span class="toc-number">2.</span> <span class="toc-text">Concepts</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GPT-or-ChatGPT"><span class="toc-number">2.1.</span> <span class="toc-text">GPT or ChatGPT</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-%E6%8F%90%E7%A4%BA%E8%AF%8D"><span class="toc-number">2.2.</span> <span class="toc-text">Prompt 提示词</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Embedings-%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">Embedings 嵌入模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Token-%E8%AF%8D%E5%85%83-%E4%BB%A3%E5%B8%81"><span class="toc-number">2.4.</span> <span class="toc-text">Token 词元&#x2F;代币</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Large-Multimodal-Model-%E5%A4%A7%E5%9E%8B%E5%A4%9A%E6%A8%A1%E6%80%81%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.5.</span> <span class="toc-text">Large Multimodal Model 大型多模态模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DALL-E"><span class="toc-number">2.6.</span> <span class="toc-text">DALL-E</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Text-To-Speech-TTS-%E6%96%87%E6%9C%AC%E8%BD%AC%E8%AF%AD%E9%9F%B3"><span class="toc-number">2.7.</span> <span class="toc-text">Text To Speech (TTS) 文本转语音</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Whisper-%E8%80%B3%E8%AF%AD"><span class="toc-number">2.8.</span> <span class="toc-text">Whisper 耳语</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Moderation-%E9%80%82%E5%BA%A6-%E5%AE%A1%E6%9F%A5%E6%A8%A1%E5%9E%8B-censorship-model"><span class="toc-number">2.9.</span> <span class="toc-text">Moderation 适度(审查模型) censorship model</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Frequency-and-presence-penalties-penal-adj-%E5%88%91%E4%BA%8B%E7%9A%84-%E9%A2%91%E7%8E%87%E5%92%8C%E5%AD%98%E5%9C%A8%E6%83%A9%E7%BD%9A"><span class="toc-number">2.10.</span> <span class="toc-text">Frequency and presence penalties (penal adj.刑事的) (频率和存在惩罚)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Prompt-Engineering-%E6%8F%90%E7%A4%BA%E8%AF%8D%E5%B7%A5%E7%A8%8B"><span class="toc-number">2.11.</span> <span class="toc-text">Prompt Engineering 提示词工程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Temperature-Parameter-%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0"><span class="toc-number">2.12.</span> <span class="toc-text">Temperature Parameter 温度参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Function-call-%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8"><span class="toc-number">2.13.</span> <span class="toc-text">Function call 函数调用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Fine-tuning-%E5%BE%AE%E8%B0%83-%E7%B2%BE%E7%BB%86%E7%9A%84%E8%B0%83%E6%95%B4"><span class="toc-number">2.14.</span> <span class="toc-text">Fine-tuning (微调) (精细的调整)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Few-Shot-Learning-%E5%B0%91%E6%A0%B7%E6%9C%AC%E8%AE%AD%E7%BB%83"><span class="toc-number">2.15.</span> <span class="toc-text">Few-Shot Learning (少样本训练)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AGI-Artificial-General-Intelligence-%E4%BA%BA%E5%B7%A5%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BD"><span class="toc-number">2.16.</span> <span class="toc-text">AGI (Artificial General Intelligence) 人工通用智能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DPO-Direct-Perfer-Optimal-%E7%9B%B4%E6%8E%A5%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96"><span class="toc-number">2.17.</span> <span class="toc-text">DPO(Direct Perfer Optimal) 直接偏好优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#NLP-Natural-Language-Processing-%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="toc-number">2.18.</span> <span class="toc-text">NLP(Natural Language Processing) 自然语言处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CV-Computer-Vision-%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="toc-number">2.19.</span> <span class="toc-text">CV (Computer Vision) 计算机视觉</span></a></li></ol></li></ol></div><article class="post post__with-toc content-card"><div class="post__header"><div class="post__expire" id="post-expired-notify"><p>This article was last updated on &lt;span id=&#34;expire-date&#34;&gt;&lt;/span&gt; days ago, the information described in the article may be outdated.</p></div><script>(() => {
            var update = Date.parse("2023-09-19"),
                date = new Date(),
                now = date.getTime(),
                expire = now - update,
                expire_days = Math.floor(expire/(24*3600*1000));
            if (expire_days >= 120) {
                document.querySelectorAll('#expire-date')[0].innerHTML = expire_days;
                document.querySelectorAll('#post-expired-notify')[0].style.display = 'block';
            }
        })();</script></div><div class="post__content"><h1 id="ChatGPT-API-学习笔记"><a href="#ChatGPT-API-学习笔记" class="headerlink" title="ChatGPT API 学习笔记"></a>ChatGPT API 学习笔记</h1><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ol><li><a target="_blank" rel="noopener" href="https://platform.openai.com/docs/introduction">Openai Offical Document</a></li></ol><h2 id="Concepts"><a href="#Concepts" class="headerlink" title="Concepts"></a>Concepts</h2><h3 id="GPT-or-ChatGPT"><a href="#GPT-or-ChatGPT" class="headerlink" title="GPT or ChatGPT"></a>GPT or ChatGPT</h3><p>OpenAI’s text generation models (often referred to as generative pre-trained transformers or “GPT” models for short)</p><p>OpenAI 的文本生成模型(通常称为生成式预训练变化者 或简称”GPT”模型)</p><h3 id="Prompt-提示词"><a href="#Prompt-提示词" class="headerlink" title="Prompt 提示词"></a>Prompt 提示词</h3><p>Designing a <code>prompt</code> is essentially how you “program” a model like GPT-4, usually by providing instructions or some examples of how to successfully complete a task.</p><p><code>prompt</code> 的设计本质上是如何”编程”一个像GPT-4这样的模型,通常是通过提供成功完成任务的说明或一些示例来完成的.</p><h3 id="Embedings-嵌入模型"><a href="#Embedings-嵌入模型" class="headerlink" title="Embedings 嵌入模型"></a>Embedings 嵌入模型</h3><p>Embeddings are a numerical representation of text.</p><p>嵌入是文本的数字表示.</p><p>An embedding is a vector representation of a piece of data (e.g. some text)</p><p>嵌入是一段数据(例如某些文本)的矢量表示.</p><p>that is meant to preserve aspects of its content and&#x2F;or its meaning.</p><p>它被用于保留其内容和&#x2F;或含义的方面.</p><p>text embedding models that take as input a text string and produce as output an embedding vector.</p><p>文本嵌入模型将文本字符串作为输入, 并将嵌入向量作为输出.</p><p>Embeddings are useful for search, clustering, recommendations, anomaly detection, classification, and more.</p><p>嵌入对于搜索、聚类、推荐、异常检测、分类等非常有用.</p><p>can be used to measure the relatedness between two pieces of text</p><p>可用于衡量两段文本之间的相关性</p><h3 id="Token-词元-代币"><a href="#Token-词元-代币" class="headerlink" title="Token 词元&#x2F;代币"></a>Token 词元&#x2F;代币</h3><p>Text generation and embeddings models process text in chunks called tokens. A token is a single unit of text, such as a word or a subword. (as English words)</p><p>Token 是文本生成和嵌入模型处理文本的块,称为词元. 词元是文本的单个单位,例如单词或子词. (如英语单词), 可以理解成, 在 LLM(Large Language Model) 中, Token 是最小的文本单位, 他维护着一个词表, 词表中的每个词都有一个对应的 Token.</p><p>tokenization &#x3D; token + ization</p><p>As a rough rule of thumb, 1 token is approximately 4 characters or 0.75 words for English text.</p><p>根据粗略的经验,1 个标记大约相当于 4 个字符或 0.75 个英文单词. 可以使用英语做 prompt , 并要求用中文输出, 来节省 token.</p><p>The limit is that for a text generation model the <strong>prompt and the generated</strong> output must be no more than the model’s maximum context limit.</p><p>对于文本生成模型, <strong>提示和生成的输出的总和</strong>不得超过模型的最大上下文长度.</p><p>For embeddings models (which do not output tokens), the input must be shorter than the model’s maximum context length.</p><p>对于嵌入模型(不输出标记), 输入必须比模型的最大上下文长度短.</p><p><strong>Both input and output tokens</strong> count towards the context limit.</p><p>输入和输出标记都计入上下文限制.</p><p>Counting tokens for chat API calls.(use Python function)</p><h3 id="Large-Multimodal-Model-大型多模态模型"><a href="#Large-Multimodal-Model-大型多模态模型" class="headerlink" title="Large Multimodal Model 大型多模态模型"></a>Large Multimodal Model 大型多模态模型</h3><p>GPT-4 is a large multimodal model (accepting text or image inputs and outputting text)</p><p>GPT-4 是一个大型多模态模型(接受文本或图像输入并输出文本)</p><p>Multilingual(Multiple Language) capabilities 多语言能力</p><h3 id="DALL-E"><a href="#DALL-E" class="headerlink" title="DALL-E"></a>DALL-E</h3><p>DALL·E is a AI system that can create realistic images and art from a description in natural language.</p><p>DALL·E 是一个人工智能系统, 可以根据自然语言的描述创建逼真的图像和艺术.</p><h3 id="Text-To-Speech-TTS-文本转语音"><a href="#Text-To-Speech-TTS-文本转语音" class="headerlink" title="Text To Speech (TTS) 文本转语音"></a>Text To Speech (TTS) 文本转语音</h3><p>TTS is an AI model that converts text to natural sounding spoken text.</p><p>TTS 是一种人工智能模型,可将文本转换为听起来自然的语音文本.</p><h3 id="Whisper-耳语"><a href="#Whisper-耳语" class="headerlink" title="Whisper 耳语"></a>Whisper 耳语</h3><p>Whisper is a general-purpose speech recognition model.</p><p>Whisper 是一种 通用目的 的语音识别模型.</p><h3 id="Moderation-适度-审查模型-censorship-model"><a href="#Moderation-适度-审查模型-censorship-model" class="headerlink" title="Moderation 适度(审查模型) censorship model"></a>Moderation 适度(审查模型) censorship model</h3><p>The Moderation models are designed to check whether content complies with OpenAI’s usage policies.</p><p>审核模型旨在检查内容是否符合 OpenAI 的使用政策.</p><p>The models provide classification capabilities(分类能力) that look for content in the following categories: hate(仇恨), hate&#x2F;threatening(仇恨&#x2F;威胁), self-harm(自残), sexual(性), sexual&#x2F;minors(性&#x2F;未成年性), violence(暴力), and violence&#x2F;graphic(暴力图像).</p><h3 id="Frequency-and-presence-penalties-penal-adj-刑事的-频率和存在惩罚"><a href="#Frequency-and-presence-penalties-penal-adj-刑事的-频率和存在惩罚" class="headerlink" title="Frequency and presence penalties (penal adj.刑事的) (频率和存在惩罚)"></a>Frequency and presence penalties (penal adj.刑事的) (频率和存在惩罚)</h3><p>can be used to reduce the possibility of sampling repetitive sequences of tokens.</p><p>可以用来减少采样重复标记序列的可能性.</p><p>如果目的只是稍微减少重复样本,那么惩罚系数的合理值约为 0.1 到 1.如果目标是强烈抑制重复,那么可以将系数增加到 2,但这会显着降低样本的质量.负值可用于增加重复的可能性.</p><h3 id="Prompt-Engineering-提示词工程"><a href="#Prompt-Engineering-提示词工程" class="headerlink" title="Prompt Engineering 提示词工程"></a>Prompt Engineering 提示词工程</h3><p>Prompt engineering can be used to improve model inference and reduce the likelihood of the model hallucinating.</p><p>提示词工程可用于改善模型推理, 减少模型产生幻觉的可能性.</p><h3 id="Temperature-Parameter-温度参数"><a href="#Temperature-Parameter-温度参数" class="headerlink" title="Temperature Parameter 温度参数"></a>Temperature Parameter 温度参数</h3><p>Lower values for temperature result in more consistent outputs (e.g. 0.2)</p><p>较低的温度值会产生更一致的输出(例如 0.2)</p><p>higher values generate more diverse(difference) and creative results (e.g. 1.0).</p><p>较高的值会产生更多样化和创造性的结果(例如 1.0).</p><p>The temperature can range is from 0 to 2.</p><p>温度范围是从 0 到 2.</p><h3 id="Function-call-函数调用"><a href="#Function-call-函数调用" class="headerlink" title="Function call 函数调用"></a>Function call 函数调用</h3><p>connect LLM to external tools. (e.g. sending an email, making a reservation, or generating code)</p><p>将大型语言模型连接到外部工具</p><h3 id="Fine-tuning-微调-精细的调整"><a href="#Fine-tuning-微调-精细的调整" class="headerlink" title="Fine-tuning (微调) (精细的调整)"></a>Fine-tuning (微调) (精细的调整)</h3><p>Fine-tuning improves on few-shot learning by training on many more examples than can fit in the prompt.</p><p>微调通过训练比 prompt 中可以容纳的更多示例, 来改进少样本学习.</p><p>Once a model has been fine-tuned, you won’t need to provide as many examples in the prompt.</p><p>一旦模型被微调, 你就不需要在 prompt 中提供太多的示例.</p><p>Fine-tuning is a method for customizing a model to better fit(vt. 安装;使……适应;) specific task, such as role-playing.</p><p>微调是自定义个性化模型的一种方法, 通过微调, 可以让模型更好地适应特定的任务. 例如指定的角色扮演(role-playing).</p><h3 id="Few-Shot-Learning-少样本训练"><a href="#Few-Shot-Learning-少样本训练" class="headerlink" title="Few-Shot Learning (少样本训练)"></a>Few-Shot Learning (少样本训练)</h3><p>Few-shot learning is a method for training a model on a small number of examples.</p><p>少样本学习是一种在少量示例上训练模型的方法.</p><p>For example, u can input a few prompt to the model, and the model can generate the output based on the prompt.</p><p>例如, 您可以向模型输入几个提示, 模型可以根据提示生成输出.</p><h3 id="AGI-Artificial-General-Intelligence-人工通用智能"><a href="#AGI-Artificial-General-Intelligence-人工通用智能" class="headerlink" title="AGI (Artificial General Intelligence) 人工通用智能"></a>AGI (Artificial General Intelligence) 人工通用智能</h3><p>AGI is a hypothetical AI that can understand and learn any intellectual task that a human being can.</p><p>AGI 是一种假设的人工智能, 可以理解和学习人类可以理解和学习的任何智力任务.</p><h3 id="DPO-Direct-Perfer-Optimal-直接偏好优化"><a href="#DPO-Direct-Perfer-Optimal-直接偏好优化" class="headerlink" title="DPO(Direct Perfer Optimal) 直接偏好优化"></a>DPO(Direct Perfer Optimal) 直接偏好优化</h3><p>DPO 是一种稳定且高效的方法, 用于微调 (fine-tuning) LLMs, 以便生成符合用户偏好的输出.</p><p>能够在不依赖复杂的基于人类反馈的强化学习 (Reinforcement Learning based on Human Feedback) 的情况下, 实现精准控制.</p><h3 id="NLP-Natural-Language-Processing-自然语言处理"><a href="#NLP-Natural-Language-Processing-自然语言处理" class="headerlink" title="NLP(Natural Language Processing) 自然语言处理"></a>NLP(Natural Language Processing) 自然语言处理</h3><h3 id="CV-Computer-Vision-计算机视觉"><a href="#CV-Computer-Vision-计算机视觉" class="headerlink" title="CV (Computer Vision) 计算机视觉"></a>CV (Computer Vision) 计算机视觉</h3></div><div class="post__license"><p><strong>Author: </strong>WhaleFall</p><p><strong>Permalink: </strong><a href="https://www.whaleluo.top/artificialintelligence/chatgpt-api-study/">https://www.whaleluo.top/artificialintelligence/chatgpt-api-study/</a></p><strong><p>文章默认使用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">CC BY-NC-SA 4.0</a> 协议进行许可，使用时请注意遵守协议。</p></strong></div><div class="post-footer__meta"><p>updated at 2023-09-19</p></div><div class="post-entry__tags"><a href="/tags/AI/" class="post-tags__link button"># AI</a><a href="/tags/ChatGPT/" class="post-tags__link button"># ChatGPT</a><a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="post-tags__link button"># 人工智能</a></div></article><div class="nav"><div class="nav__prev"><a href="/china-documentary/" class="nav__link"><div><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="24" height="24"><path d="M589.088 790.624L310.464 512l278.624-278.624 45.248 45.248L400.96 512l233.376 233.376z" fill="#808080"></path></svg></div><div><div class="nav__label">Previous Post</div><div class="nav__title">纪实、深度、冷门——中国独立纪录片推荐</div></div></a></div><div class="nav__next"><a href="/artificialintelligence/gpt-sovits-experiment/" class="nav__link"><div><div class="nav__label">Next Post</div><div class="nav__title">GPT-SoVITS 小实验</div></div><div><svg viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" width="24" height="24"><path d="M434.944 790.624l-45.248-45.248L623.04 512l-233.376-233.376 45.248-45.248L713.568 512z" fill="#808080"></path></svg></div></a></div></div><div class="post__comments post__with-toc content-card" id="comment"><h4>Comments</h4><div id="gitalk-container"></div></div></main><footer class="footer"><a href="#" class="button" id="b2t" aria-label="Back to Top" title="Back to Top"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1024 1024" width="32" height="32"><path d="M233.376 722.752L278.624 768 512 534.624 745.376 768l45.248-45.248L512 444.128zM192 352h640V288H192z" fill="currentColor"></path></svg> </a><span id="busuanzi_container_site_uv" hidden><span></span> <span id="busuanzi_value_site_uv"></span> <span>Viewers</span> <span>|</span> </span><span id="busuanzi_container_site_pv" hidden><span></span> <span id="busuanzi_value_site_pv"></span> <span>Views</span></span><p class="footer-copyright">Copyright © 2018&nbsp;-&nbsp;2024 <a href="/">😊落落のBlog😊</a></p><p>Powered by <a href="https://hexo.io" target="_blank">Hexo</a> | Theme - <a href="https://github.com/ChrAlpha/hexo-theme-cards" target="_blank">Cards</a></p></footer></div><script defer src="https://api.whaleluo.top/file/?url=https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.1.0/dist/lazyload.min.js"></script><script>window.lazyLoadOptions={elements_selector:".lazy",threshold:0}</script><script defer src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon='{"token": "e052e3fc47004feab6ae8122cfeec660"}'></script><script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js"></script><link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"><script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js"></script><script>let lazyloadT = Boolean('true'),
            auto_fancybox = Boolean('true')
        if (auto_fancybox) {
            $(".post__content").find('img').each(function () {
                var element = document.createElement("a");
                $(element).attr("data-fancybox", "gallery");
                $(element).attr("href", $(this).attr("src"));
                if (lazyloadT) {
                    $(element).attr("href", $(this).attr("data-srcset"));
                }
                $(this).wrap(element);
            });
        } else {
            $(".post__content").find("fancybox").find('img').each(function () {
                var element = document.createElement("a");
                $(element).attr("data-fancybox", "gallery");
                $(element).attr("href", $(this).attr("src"));
                if (lazyloadT) {
                    $(element).attr("href", $(this).attr("data-srcset"));
                }
                $(this).wrap(element);
            });
        }</script><script>function loadComment() {
            let e, i;
            (e = document.createElement("script")).src = 'https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js',
            document.body.appendChild(e);
            e.onload = () => {
                var gitalk = new Gitalk({
                    clientID: 'b2fd920dada050fed5b3',
                    clientSecret: '5c847cefe7df2df634886eafa178877899404378',
                    repo: 'WhaleFell.github.io',
                    owner: 'WhaleFell',
                    admin: 'WhaleFell',
                    id: window.location.pathname,
                    distractionFreeMode: false
                });
                gitalk.render('gitalk-container');
            };
            (i = document.createElement("link")).rel = "stylesheet",
            i.href = 'https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css',
            document.head.appendChild(i);
        }
    
        var runningOnBrowser = typeof window !== "undefined";
        var isBot = runningOnBrowser && !("onscroll" in window) || typeof navigator !== "undefined" && /(gle|ing|ro|msn)bot|crawl|spider|yand|duckgo/i.test(navigator.userAgent);
        var supportsIntersectionObserver = runningOnBrowser && "IntersectionObserver" in window;
    
        setTimeout(function () {
            if (!isBot && supportsIntersectionObserver) {
                var comment_observer = new IntersectionObserver(function(entries) {
                    if (entries[0].isIntersecting) {
                        loadComment();
                        comment_observer.disconnect();
                    }
                }, { threshold: [0] });
                comment_observer.observe(document.getElementById('comment'));
            } else {
                loadComment();
            }
        }, 1);</script></body></html>